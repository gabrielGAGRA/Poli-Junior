{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "openai.api_key = 'sk-proj-YLvCCJmFWMusZAH0wYuAT3BlbkFJzuOeCfODAfNJAaAONKg6'\n",
    "client = OpenAI(api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data_fixed_size(data, chunk_size):\n",
    "    chunks = []\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        chunks.append(data[i:i + chunk_size])\n",
    "    return chunks\n",
    "\n",
    "def save_chunks_to_files(chunks):\n",
    "    file_names = []\n",
    "    for i, chunk in enumerate(chunks, start=1):\n",
    "        file_name = f\"parte_da_base_de_saidas_{i}.json\"\n",
    "        with open(file_name, 'w', encoding='utf-8') as f:\n",
    "            json.dump(chunk, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"File {file_name} has been created and saved.\")\n",
    "        file_names.append(file_name)\n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File parte_da_base_de_saidas_1.json has been created and saved.\n",
      "File parte_da_base_de_saidas_2.json has been created and saved.\n",
      "File parte_da_base_de_saidas_3.json has been created and saved.\n",
      "File parte_da_base_de_saidas_4.json has been created and saved.\n",
      "File parte_da_base_de_saidas_5.json has been created and saved.\n",
      "File parte_da_base_de_saidas_6.json has been created and saved.\n",
      "File parte_da_base_de_saidas_7.json has been created and saved.\n",
      "File parte_da_base_de_saidas_8.json has been created and saved.\n",
      "File parte_da_base_de_saidas_9.json has been created and saved.\n",
      "File parte_da_base_de_saidas_10.json has been created and saved.\n",
      "File parte_da_base_de_saidas_11.json has been created and saved.\n",
      "File parte_da_base_de_saidas_12.json has been created and saved.\n",
      "File parte_da_base_de_saidas_13.json has been created and saved.\n",
      "File parte_da_base_de_saidas_14.json has been created and saved.\n",
      "File parte_da_base_de_saidas_15.json has been created and saved.\n",
      "File parte_da_base_de_saidas_16.json has been created and saved.\n",
      "File parte_da_base_de_saidas_17.json has been created and saved.\n",
      "File parte_da_base_de_saidas_18.json has been created and saved.\n",
      "File parte_da_base_de_saidas_19.json has been created and saved.\n",
      "File parte_da_base_de_saidas_20.json has been created and saved.\n",
      "File parte_da_base_de_saidas_21.json has been created and saved.\n",
      "File parte_da_base_de_saidas_22.json has been created and saved.\n",
      "File parte_da_base_de_saidas_23.json has been created and saved.\n",
      "File parte_da_base_de_saidas_24.json has been created and saved.\n",
      "File parte_da_base_de_saidas_25.json has been created and saved.\n",
      "File parte_da_base_de_saidas_26.json has been created and saved.\n",
      "File parte_da_base_de_saidas_27.json has been created and saved.\n",
      "File parte_da_base_de_saidas_28.json has been created and saved.\n",
      "File parte_da_base_de_saidas_29.json has been created and saved.\n",
      "File parte_da_base_de_saidas_30.json has been created and saved.\n",
      "File parte_da_base_de_saidas_31.json has been created and saved.\n",
      "File parte_da_base_de_saidas_32.json has been created and saved.\n",
      "File parte_da_base_de_saidas_33.json has been created and saved.\n",
      "File parte_da_base_de_saidas_34.json has been created and saved.\n",
      "File parte_da_base_de_saidas_35.json has been created and saved.\n",
      "File parte_da_base_de_saidas_36.json has been created and saved.\n",
      "File parte_da_base_de_saidas_37.json has been created and saved.\n",
      "File parte_da_base_de_saidas_38.json has been created and saved.\n",
      "File parte_da_base_de_saidas_39.json has been created and saved.\n",
      "File parte_da_base_de_saidas_40.json has been created and saved.\n",
      "File parte_da_base_de_saidas_41.json has been created and saved.\n",
      "File parte_da_base_de_saidas_42.json has been created and saved.\n",
      "File parte_da_base_de_saidas_43.json has been created and saved.\n",
      "File parte_da_base_de_saidas_44.json has been created and saved.\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON data from the file\n",
    "with open(r'C:\\Users\\gabri\\Documents\\PROJETOS\\PY\\PJ_Code\\Nutax\\Modelo IA\\Dados_JSON_limpos\\novo-base_saidas_202407142342.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Example usage\n",
    "chunk_size = 4100\n",
    "chunks = chunk_data_fixed_size(data, chunk_size)\n",
    "file_names = save_chunks_to_files(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the JSON files\n",
    "directory_path = r'C:\\Users\\gabri\\Documents\\PROJETOS\\PY\\PJ_Code\\Nutax\\Modelo IA\\Separados- JSON'\n",
    "\n",
    "# List all JSON files in the directory\n",
    "file_paths = [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith('.json')]\n",
    "file_streams = [open(path, 'rb') for path in file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m file_batch \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_stores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_and_poll\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvector_store_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvs_pv8VIaf39XpWgHxL1zUdUmnw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_streams\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\resources\\beta\\vector_stores\\file_batches.py:345\u001b[0m, in \u001b[0;36mFileBatches.upload_and_poll\u001b[1;34m(self, vector_store_id, files, max_concurrency, file_ids, poll_interval_ms, chunking_strategy)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    343\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(future\u001b[38;5;241m.\u001b[39mresult())\n\u001b[1;32m--> 345\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_and_poll\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvector_store_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvector_store_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfile_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoll_interval_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoll_interval_ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunking_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunking_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\resources\\beta\\vector_stores\\file_batches.py:186\u001b[0m, in \u001b[0;36mFileBatches.create_and_poll\u001b[1;34m(self, vector_store_id, file_ids, poll_interval_ms, chunking_strategy)\u001b[0m\n\u001b[0;32m    180\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    181\u001b[0m     vector_store_id\u001b[38;5;241m=\u001b[39mvector_store_id,\n\u001b[0;32m    182\u001b[0m     file_ids\u001b[38;5;241m=\u001b[39mfile_ids,\n\u001b[0;32m    183\u001b[0m     chunking_strategy\u001b[38;5;241m=\u001b[39mchunking_strategy,\n\u001b[0;32m    184\u001b[0m )\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# TODO: don't poll unless necessary??\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvector_store_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvector_store_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoll_interval_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoll_interval_ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\resources\\beta\\vector_stores\\file_batches.py:298\u001b[0m, in \u001b[0;36mFileBatches.poll\u001b[1;34m(self, batch_id, vector_store_id, poll_interval_ms)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    296\u001b[0m             poll_interval_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll_interval_ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_resource.py:27\u001b[0m, in \u001b[0;36mSyncAPIResource._sleep\u001b[1;34m(self, seconds)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sleep\u001b[39m(\u001b[38;5;28mself\u001b[39m, seconds: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id='vs_pv8VIaf39XpWgHxL1zUdUmnw',\n",
    "    files=file_streams\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
